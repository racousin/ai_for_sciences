{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1: Transfer Learning for Medical Image Classification\n",
    "\n",
    "**Day 3 - AI for Sciences Summer School**\n",
    "\n",
    "**Instructor:** Raphael Cousin\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/racousin/ai_for_sciences/blob/main/day3/tp1.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## The BloodMNIST Challenge\n",
    "\n",
    "**BloodMNIST** is a medical image dataset from the MedMNIST collection:\n",
    "- **17,092 images** of blood cells (28x28 pixels, RGB)\n",
    "- **8 classes** of blood cell types\n",
    "- Real microscopy images from blood smear analysis\n",
    "\n",
    "```\n",
    "                    BLOOD SMEAR ANALYSIS\n",
    "    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "    â•‘                                               â•‘\n",
    "    â•‘     ğŸ”´  Red Blood Cells (various types)       â•‘\n",
    "    â•‘     âšª  White Blood Cells (various types)     â•‘\n",
    "    â•‘     ğŸŸ¡  Platelets                             â•‘\n",
    "    â•‘                                               â•‘\n",
    "    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "              â†“ Microscopy Image â†“\n",
    "            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "            â”‚     28x28 RGB       â”‚\n",
    "            â”‚       Image         â”‚\n",
    "            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                      â†“\n",
    "              AI Classification\n",
    "                      â†“\n",
    "           \"Neutrophil\" (class 2)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. How to **explore and visualize** medical image datasets\n",
    "2. How **data augmentation** improves model robustness\n",
    "3. How to build a **simple CNN baseline** from scratch\n",
    "4. How to use **transfer learning** with a frozen backbone\n",
    "5. How to **fine-tune** a complete pre-trained model\n",
    "6. When to use each approach based on your data and constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Setup and Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q medmnist torchvision timm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import medmnist\n",
    "from medmnist import INFO\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the BloodMNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Dataset information\ndata_flag = 'bloodmnist'\ninfo = INFO[data_flag]\nn_classes = len(info['label'])\n\nprint(\"BloodMNIST Dataset Information\")\nprint(\"=\" * 50)\nprint(f\"Task: {info['task']}\")\nprint(f\"Number of channels: {info['n_channels']}\")\nprint(f\"Number of classes: {n_classes}\")\nprint(f\"Image size: {info['n_channels']} x 28 x 28\")\nprint(f\"\\nClass labels:\")\nfor i, label in info['label'].items():\n    print(f\"  {i}: {label}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets with basic transforms\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "# Basic transform: just convert to tensor and normalize\n",
    "transform_basic = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Load train, validation, and test sets\n",
    "train_dataset = DataClass(split='train', transform=transform_basic, download=True)\n",
    "val_dataset = DataClass(split='val', transform=transform_basic, download=True)\n",
    "test_dataset = DataClass(split='test', transform=transform_basic, download=True)\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"  Training:   {len(train_dataset):,} images\")\n",
    "print(f\"  Validation: {len(val_dataset):,} images\")\n",
    "print(f\"  Test:       {len(test_dataset):,} images\")\n",
    "print(f\"  Total:      {len(train_dataset) + len(val_dataset) + len(test_dataset):,} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Sample Images\n",
    "\n",
    "Before building any model, it's essential to **look at your data**. This helps you understand:\n",
    "- What the images look like\n",
    "- How different classes appear\n",
    "- Potential challenges (image quality, class similarity, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names\n",
    "class_names = list(info['label'].values())\n",
    "\n",
    "# Function to denormalize images for display\n",
    "def denormalize(tensor):\n",
    "    \"\"\"Convert normalized tensor back to displayable image.\"\"\"\n",
    "    return tensor * 0.5 + 0.5\n",
    "\n",
    "# Show random samples from each class\n",
    "fig, axes = plt.subplots(2, 4, figsize=(12, 6))\n",
    "fig.suptitle('Sample Images from Each Blood Cell Class', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Get samples for each class\n",
    "for class_idx in range(8):\n",
    "    # Find images of this class\n",
    "    class_indices = [i for i, (_, label) in enumerate(train_dataset) if label[0] == class_idx]\n",
    "    \n",
    "    if class_indices:\n",
    "        # Get a random sample\n",
    "        sample_idx = class_indices[np.random.randint(len(class_indices))]\n",
    "        image, label = train_dataset[sample_idx]\n",
    "        \n",
    "        # Plot\n",
    "        ax = axes[class_idx // 4, class_idx % 4]\n",
    "        img_display = denormalize(image).permute(1, 2, 0).numpy()\n",
    "        ax.imshow(img_display)\n",
    "        ax.set_title(f'{class_idx}: {class_names[class_idx]}', fontsize=10)\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class distribution\n",
    "train_labels = [label[0] for _, label in train_dataset]\n",
    "unique, counts = np.unique(train_labels, return_counts=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, 8))\n",
    "bars = ax.bar(class_names, counts, color=colors, edgecolor='gray')\n",
    "\n",
    "ax.set_xlabel('Blood Cell Type', fontsize=11)\n",
    "ax.set_ylabel('Number of Images', fontsize=11)\n",
    "ax.set_title('Class Distribution in Training Set', fontsize=12, fontweight='bold')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add count labels on bars\n",
    "for bar, count in zip(bars, counts):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 20,\n",
    "            f'{count}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nClass imbalance ratio: {max(counts)/min(counts):.1f}x\")\n",
    "print(f\"Most common: {class_names[np.argmax(counts)]} ({max(counts)} samples)\")\n",
    "print(f\"Least common: {class_names[np.argmin(counts)]} ({min(counts)} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Understanding the Data\n",
    "\n",
    "Look at the sample images and class distribution:\n",
    "\n",
    "1. **Visual inspection**: Which cell types look most similar to each other? Which look most distinct?\n",
    "\n",
    "2. **Class imbalance**: Is the dataset balanced? How might this affect model training?\n",
    "\n",
    "3. **Image quality**: The images are only 28x28 pixels. What challenges might this create for classification?\n",
    "\n",
    "4. **For your research**: What medical imaging data do you work with? What are its characteristics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Data Augmentation\n",
    "\n",
    "**Data augmentation** artificially increases training data by applying random transformations:\n",
    "- Helps models generalize better\n",
    "- Reduces overfitting\n",
    "- Simulates real-world variations\n",
    "\n",
    "For medical images, we must choose augmentations that make **biological sense**:\n",
    "- Rotation: Blood cells can appear at any angle\n",
    "- Flipping: Cells are symmetric\n",
    "- Color jitter: Accounts for staining variations\n",
    "- NOT recommended: Extreme distortions that change cell morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize different augmentation techniques\n",
    "\n",
    "# Get a sample image\n",
    "sample_image, sample_label = train_dataset[0]\n",
    "\n",
    "# Define different augmentations\n",
    "augmentations = {\n",
    "    'Original': transforms.Compose([]),\n",
    "    'Horizontal Flip': transforms.RandomHorizontalFlip(p=1.0),\n",
    "    'Vertical Flip': transforms.RandomVerticalFlip(p=1.0),\n",
    "    'Rotation (30)': transforms.RandomRotation(30),\n",
    "    'Color Jitter': transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "    'Random Crop': transforms.RandomResizedCrop(28, scale=(0.8, 1.0)),\n",
    "}\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "fig.suptitle('Data Augmentation Examples', fontsize=14, fontweight='bold')\n",
    "\n",
    "for idx, (name, aug) in enumerate(augmentations.items()):\n",
    "    ax = axes[idx // 3, idx % 3]\n",
    "    \n",
    "    if name == 'Original':\n",
    "        img_aug = sample_image\n",
    "    else:\n",
    "        # Apply augmentation\n",
    "        img_aug = aug(denormalize(sample_image))\n",
    "        if not isinstance(img_aug, torch.Tensor):\n",
    "            img_aug = transforms.ToTensor()(img_aug)\n",
    "    \n",
    "    # Display\n",
    "    if name == 'Original':\n",
    "        img_display = denormalize(img_aug).permute(1, 2, 0).numpy()\n",
    "    else:\n",
    "        img_display = img_aug.permute(1, 2, 0).numpy()\n",
    "        img_display = np.clip(img_display, 0, 1)\n",
    "    \n",
    "    ax.imshow(img_display)\n",
    "    ax.set_title(name, fontsize=11)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Design Your Augmentation Pipeline\n",
    "\n",
    "Create an augmentation pipeline appropriate for blood cell images. Consider:\n",
    "- Which transformations make biological sense?\n",
    "- What intensity of augmentation is appropriate?\n",
    "- Should you combine multiple augmentations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Design your augmentation pipeline!\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    # Add your augmentations here!  # <-- Modify this!\n",
    "    # Hint: Consider RandomHorizontalFlip, RandomRotation, ColorJitter\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Test transform (no augmentation)\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "print(\"Your augmentation pipeline:\")\n",
    "print(transform_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Augmentation Choices\n",
    "\n",
    "1. Why might **random rotation** be a good augmentation for blood cells?\n",
    "\n",
    "2. Why might **extreme stretching or shearing** be a bad augmentation for cell classification?\n",
    "\n",
    "3. How does **color jitter** help with medical images that may have staining variations?\n",
    "\n",
    "4. What augmentations would be appropriate (or inappropriate) for your research domain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload datasets with your augmentation\n",
    "train_dataset_aug = DataClass(split='train', transform=transform_train, download=True)\n",
    "val_dataset_test = DataClass(split='val', transform=transform_test, download=True)\n",
    "test_dataset_test = DataClass(split='test', transform=transform_test, download=True)\n",
    "\n",
    "# Create data loaders\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset_aug, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Data loaders created:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches:   {len(val_loader)}\")\n",
    "print(f\"  Test batches:  {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Baseline - Simple CNN from Scratch\n",
    "\n",
    "Before using pre-trained models, let's establish a **baseline** with a simple CNN.\n",
    "\n",
    "This helps us understand:\n",
    "- What accuracy can we achieve with a small, custom model?\n",
    "- How much improvement do pre-trained models provide?\n",
    "\n",
    "```\n",
    "Simple CNN Architecture:\n",
    "\n",
    "Input (3x28x28) â†’ Conv(32) â†’ ReLU â†’ MaxPool\n",
    "              â†’ Conv(64) â†’ ReLU â†’ MaxPool  \n",
    "              â†’ Conv(128) â†’ ReLU â†’ AdaptivePool\n",
    "              â†’ Flatten â†’ Linear(8) â†’ Output\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"A simple CNN for blood cell classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=8):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            # First conv block\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Second conv block\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            # Third conv block\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1)  # Global average pooling\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Create model\n",
    "model_scratch = SimpleCNN(num_classes=8).to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model_scratch.parameters())\n",
    "trainable_params = sum(p.numel() for p in model_scratch.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Simple CNN created!\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in tqdm(loader, desc='Training', leave=False):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.squeeze().long().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.squeeze().long().to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    return running_loss / total, 100. * correct / total\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs, lr, model_name):\n",
    "    \"\"\"Full training loop with history tracking.\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_acc = 0\n",
    "    \n",
    "    print(f\"\\nTraining {model_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "        scheduler.step()\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "            print(f\"Epoch {epoch+1:3d}/{epochs}: \"\n",
    "                  f\"Train Loss={train_loss:.4f}, Train Acc={train_acc:.1f}%, \"\n",
    "                  f\"Val Loss={val_loss:.4f}, Val Acc={val_acc:.1f}%\")\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "    \n",
    "    print(f\"\\nBest Validation Accuracy: {best_acc:.2f}%\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Baseline CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the simple CNN\n",
    "EPOCHS_BASELINE = 20\n",
    "LR_BASELINE = 0.001\n",
    "\n",
    "history_scratch = train_model(\n",
    "    model_scratch, train_loader, val_loader,\n",
    "    epochs=EPOCHS_BASELINE, lr=LR_BASELINE, model_name=\"Simple CNN (from scratch)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax1.plot(history_scratch['train_acc'], label='Train', linewidth=2)\n",
    "ax1.plot(history_scratch['val_acc'], label='Validation', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Accuracy (%)')\n",
    "ax1.set_title('Simple CNN - Accuracy', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(history_scratch['train_loss'], label='Train', linewidth=2)\n",
    "ax2.plot(history_scratch['val_loss'], label='Validation', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('Simple CNN - Loss', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Analyzing the Baseline\n",
    "\n",
    "Look at the training curves:\n",
    "\n",
    "1. Is the model **overfitting**? (Gap between train and validation accuracy)\n",
    "\n",
    "2. Has the model **converged**? (Validation accuracy plateaued)\n",
    "\n",
    "3. What's the **final validation accuracy**? Is this good enough for clinical use?\n",
    "\n",
    "4. What could we do to **improve** this baseline? (More layers? Regularization? More data?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Transfer Learning - Frozen Backbone\n",
    "\n",
    "**Transfer learning** uses models pre-trained on large datasets (like ImageNet with 14M images).\n",
    "\n",
    "**Strategy 1: Frozen Backbone**\n",
    "- Use pre-trained feature extractor (frozen = no gradient updates)\n",
    "- Only train a new classification head\n",
    "- Fast training, less data needed\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Pre-trained ResNet18         â”‚    â”‚  New Classifier â”‚\n",
    "â”‚   (FROZEN - no training)       â”‚ â†’  â”‚   (TRAINED)     â”‚\n",
    "â”‚   Features from ImageNet       â”‚    â”‚   8 classes     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pre-trained models, we need 224x224 images with ImageNet normalization\n",
    "transform_pretrained_train = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_pretrained_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Reload datasets with new transforms\n",
    "train_dataset_pt = DataClass(split='train', transform=transform_pretrained_train, download=True)\n",
    "val_dataset_pt = DataClass(split='val', transform=transform_pretrained_test, download=True)\n",
    "test_dataset_pt = DataClass(split='test', transform=transform_pretrained_test, download=True)\n",
    "\n",
    "train_loader_pt = DataLoader(train_dataset_pt, batch_size=32, shuffle=True, num_workers=2)\n",
    "val_loader_pt = DataLoader(val_dataset_pt, batch_size=32, shuffle=False, num_workers=2)\n",
    "test_loader_pt = DataLoader(test_dataset_pt, batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "print(\"Data loaders for pre-trained models created!\")\n",
    "print(f\"Image size: 224x224 (upscaled from 28x28)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Create a Frozen Backbone Model\n",
    "\n",
    "Load a pre-trained ResNet18 and:\n",
    "1. **Freeze** all backbone parameters (set `requires_grad = False`)\n",
    "2. **Replace** the final classification layer with a new one for 8 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet18\n",
    "model_frozen = models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "# TODO: Freeze all backbone parameters\n",
    "# Hint: Loop through model.parameters() and set requires_grad = False\n",
    "# <-- Add your code here!\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Replace the final fully connected layer\n",
    "# The original fc layer is: model.fc with in_features = 512, out_features = 1000 (ImageNet classes)\n",
    "# We need out_features = 8 (our blood cell classes)\n",
    "num_features = model_frozen.fc.in_features\n",
    "model_frozen.fc = nn.Linear(num_features, 8)  # This layer will be trainable by default\n",
    "\n",
    "model_frozen = model_frozen.to(device)\n",
    "\n",
    "# Check parameters\n",
    "total_params = sum(p.numel() for p in model_frozen.parameters())\n",
    "trainable_params = sum(p.numel() for p in model_frozen.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"ResNet18 (Frozen Backbone)\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Frozen parameters: {total_params - trainable_params:,}\")\n",
    "print(f\"  Trainable ratio: {100*trainable_params/total_params:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Understanding Frozen Backbones\n",
    "\n",
    "1. **Why freeze the backbone?** What advantage does this provide?\n",
    "\n",
    "2. How many parameters are trainable vs frozen? What does this mean for training speed?\n",
    "\n",
    "3. The backbone was trained on **ImageNet** (dogs, cars, etc.). Why might it still work for **blood cells**?\n",
    "\n",
    "4. When might a frozen backbone **not work well**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the frozen backbone model\n",
    "EPOCHS_FROZEN = 10\n",
    "LR_FROZEN = 0.001  # Can use higher LR since we're only training the classifier\n",
    "\n",
    "history_frozen = train_model(\n",
    "    model_frozen, train_loader_pt, val_loader_pt,\n",
    "    epochs=EPOCHS_FROZEN, lr=LR_FROZEN, model_name=\"ResNet18 (Frozen Backbone)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: Transfer Learning - Full Fine-tuning\n",
    "\n",
    "**Strategy 2: Full Fine-tuning**\n",
    "- Start with pre-trained weights\n",
    "- Train ALL layers (backbone + classifier)\n",
    "- Use a **lower learning rate** to avoid destroying pre-trained features\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚   Pre-trained ResNet18         â”‚    â”‚  New Classifier â”‚\n",
    "â”‚   (TRAINED - small LR)         â”‚ â†’  â”‚   (TRAINED)     â”‚\n",
    "â”‚   Adapt features to domain     â”‚    â”‚   8 classes     â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Create a Full Fine-tuning Model\n",
    "\n",
    "Load a new pre-trained ResNet18 where ALL parameters are trainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load pre-trained ResNet18 for full fine-tuning\n",
    "model_finetune = models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "# TODO: Replace the final layer (but DON'T freeze any parameters)\n",
    "# <-- Add your code here!\n",
    "\n",
    "\n",
    "\n",
    "model_finetune = model_finetune.to(device)\n",
    "\n",
    "# Check parameters\n",
    "total_params = sum(p.numel() for p in model_finetune.parameters())\n",
    "trainable_params = sum(p.numel() for p in model_finetune.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"ResNet18 (Full Fine-tuning)\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Trainable ratio: {100*trainable_params/total_params:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with full fine-tuning\n",
    "# Note: Use LOWER learning rate to preserve pre-trained features\n",
    "EPOCHS_FINETUNE = 15\n",
    "LR_FINETUNE = 0.0001  # 10x smaller than frozen backbone!\n",
    "\n",
    "history_finetune = train_model(\n",
    "    model_finetune, train_loader_pt, val_loader_pt,\n",
    "    epochs=EPOCHS_FINETUNE, lr=LR_FINETUNE, model_name=\"ResNet18 (Full Fine-tuning)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Comparing Training Strategies\n",
    "\n",
    "1. Why do we use a **lower learning rate** for full fine-tuning compared to frozen backbone?\n",
    "\n",
    "2. Full fine-tuning takes longer per epoch. Why?\n",
    "\n",
    "3. When would you choose frozen backbone vs full fine-tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "histories = [\n",
    "    (history_scratch, 'Simple CNN (scratch)'),\n",
    "    (history_frozen, 'ResNet18 (frozen)'),\n",
    "    (history_finetune, 'ResNet18 (fine-tuned)'),\n",
    "]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "\n",
    "for (history, label), color in zip(histories, colors):\n",
    "    ax1.plot(history['val_acc'], label=label, linewidth=2, color=color)\n",
    "    ax2.plot(history['val_loss'], label=label, linewidth=2, color=color)\n",
    "\n",
    "ax1.set_xlabel('Epoch', fontsize=11)\n",
    "ax1.set_ylabel('Validation Accuracy (%)', fontsize=11)\n",
    "ax1.set_title('Model Comparison - Validation Accuracy', fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.set_xlabel('Epoch', fontsize=11)\n",
    "ax2.set_ylabel('Validation Loss', fontsize=11)\n",
    "ax2.set_title('Model Comparison - Validation Loss', fontsize=12, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison table\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"                      FINAL MODEL COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Model':<30} {'Best Val Acc':<15} {'Final Val Acc':<15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for history, label in histories:\n",
    "    best_acc = max(history['val_acc'])\n",
    "    final_acc = history['val_acc'][-1]\n",
    "    print(f\"{label:<30} {best_acc:<15.2f} {final_acc:<15.2f}\")\n",
    "\n",
    "print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Best Model on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the fine-tuned model on test set\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "test_loss, test_acc = evaluate(model_finetune, test_loader_pt, criterion, device)\n",
    "\n",
    "print(f\"\\nTest Set Performance (ResNet18 Fine-tuned):\")\n",
    "print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "print(f\"  Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Get predictions\n",
    "model_finetune.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader_pt:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model_finetune(inputs)\n",
    "        _, preds = outputs.max(1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.squeeze().numpy())\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names, ax=ax)\n",
    "ax.set_xlabel('Predicted', fontsize=11)\n",
    "ax.set_ylabel('Actual', fontsize=11)\n",
    "ax.set_title('Confusion Matrix - ResNet18 Fine-tuned', fontsize=12, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Final Analysis\n",
    "\n",
    "1. Which cell types are most often **confused** with each other? Does this make biological sense?\n",
    "\n",
    "2. Looking at the precision and recall per class, which classes are **hardest to classify**?\n",
    "\n",
    "3. Is the model performance **good enough for clinical use**? What accuracy would you need?\n",
    "\n",
    "4. What further improvements could you make? (More data? Better augmentation? Larger model?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary\n",
    "\n",
    "## What We Built\n",
    "\n",
    "```\n",
    "Approach 1: Simple CNN from Scratch\n",
    "    28x28 â†’ Custom CNN (374K params) â†’ 8 classes\n",
    "    \n",
    "Approach 2: Frozen Backbone\n",
    "    224x224 â†’ ResNet18 (frozen) â†’ Linear(512, 8) â†’ 8 classes\n",
    "    \n",
    "Approach 3: Full Fine-tuning  \n",
    "    224x224 â†’ ResNet18 (all trainable) â†’ Linear(512, 8) â†’ 8 classes\n",
    "```\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "| Approach | Pros | Cons | When to Use |\n",
    "|----------|------|------|-------------|\n",
    "| **From Scratch** | Full control, small model | Needs lots of data | Large datasets, unique domains |\n",
    "| **Frozen Backbone** | Fast, little data needed | Limited adaptation | Quick prototyping, small datasets |\n",
    "| **Full Fine-tuning** | Best performance | Slower, may overfit | When you need max accuracy |\n",
    "\n",
    "## Transfer Learning Works Because:\n",
    "\n",
    "1. **Low-level features transfer**: Edges, textures, shapes are universal\n",
    "2. **Pre-training on large data**: ImageNet provides rich representations\n",
    "3. **Domain adaptation**: Fine-tuning adapts features to your specific task\n",
    "\n",
    "## This Pattern Works Across Domains\n",
    "\n",
    "| Domain | Pre-trained Model | Application |\n",
    "|--------|-------------------|-------------|\n",
    "| Medical imaging | ResNet, EfficientNet | X-ray, CT, microscopy |\n",
    "| Satellite imagery | ResNet | Land use, crop analysis |\n",
    "| Scientific images | ResNet, ViT | Cell segmentation, particle physics |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reflection Questions\n",
    "\n",
    "1. **In your research**, what imaging tasks could benefit from transfer learning?\n",
    "\n",
    "2. **What pre-trained models** might be most relevant to your domain? (Medical? Satellite? General?)\n",
    "\n",
    "3. **How much labeled data** do you have? Would frozen backbone or fine-tuning be more appropriate?\n",
    "\n",
    "4. **What domain-specific augmentations** would make sense for your data?\n",
    "\n",
    "5. **What accuracy level** would be needed for your application to be useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bonus Exercises\n",
    "\n",
    "If you have time, try these extensions:\n",
    "\n",
    "1. **Try a different architecture**: Replace ResNet18 with EfficientNet-B0\n",
    "\n",
    "2. **Learning rate scheduling**: Implement differential learning rates (lower for backbone, higher for classifier)\n",
    "\n",
    "3. **More augmentation**: Add CutOut, MixUp, or other modern augmentation techniques\n",
    "\n",
    "4. **Class imbalance**: Handle the imbalanced classes with weighted loss or oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: Try EfficientNet-B0\n",
    "import timm\n",
    "\n",
    "# TODO: Load EfficientNet-B0 and fine-tune it\n",
    "# model_efficient = timm.create_model('efficientnet_b0', pretrained=True, num_classes=8)\n",
    "# model_efficient = model_efficient.to(device)\n",
    "\n",
    "# Your code here..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}