{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP2 - Part 1: From Text to Vectors\n",
    "\n",
    "**Day 2 - AI for Sciences Winter School**\n",
    "\n",
    "**Instructor:** Raphael Cousin\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/racousin/ai_for_sciences/blob/main/day2/tp2_part1.ipynb)\n",
    "\n",
    "---\n",
    "\n",
    "## Objectives\n",
    "\n",
    "By the end of this practical, you will understand:\n",
    "\n",
    "1. **The pipeline**: Raw data â†’ Tokens â†’ Numbers â†’ Embeddings\n",
    "2. **What embeddings are**: Dense vector representations that capture meaning\n",
    "3. **Why embeddings matter**: Similar things have similar vectors\n",
    "4. **How to measure similarity**: Cosine similarity and distance in embedding space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# The Big Picture: Why Do We Need Embeddings?\n",
    "\n",
    "**The fundamental problem**: Neural networks only understand numbers, not text, molecules, or proteins.\n",
    "\n",
    "**The solution**: Convert everything into **vectors** (lists of numbers).\n",
    "\n",
    "But not just any vectorsâ€”we want vectors where **similar things are close together**.\n",
    "\n",
    "```\n",
    "\"King\" â†’ [0.2, -0.4, 0.8, 0.1, ...] (384 numbers)\n",
    "\"Queen\" â†’ [0.3, -0.3, 0.7, 0.2, ...] (384 numbers)  â† Close to \"King\"!\n",
    "\"Banana\" â†’ [-0.5, 0.9, -0.2, 0.6, ...] (384 numbers)  â† Far from both\n",
    "```\n",
    "\n",
    "This is the key insight of **embeddings**: meaning becomes geometry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: The Complete Pipeline\n",
    "\n",
    "Let's trace the journey from raw text to embeddings:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚  Raw Text   â”‚ â†’  â”‚   Tokens     â”‚ â†’  â”‚  Token IDs   â”‚ â†’  â”‚    Embeddings    â”‚\n",
    "â”‚  (string)   â”‚    â”‚  (subwords)  â”‚    â”‚  (integers)  â”‚    â”‚ (dense vectors)  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "\"The cat sat\"  â†’  [\"The\", \"cat\", \"sat\"] â†’  [464, 3797, 3332]  â†’  [[0.1, -0.2, ...], \n",
    "                                                                   [0.3, 0.5, ...],\n",
    "                                                                   [-0.1, 0.4, ...]]\n",
    "```\n",
    "\n",
    "**Key question**: What makes a good embedding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers sentence-transformers torch numpy matplotlib scikit-learn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: What Are Embeddings?\n",
    "\n",
    "An **embedding** is a vector representation where:\n",
    "- Each dimension captures some aspect of meaning\n",
    "- Similar items have similar vectors\n",
    "- Operations on vectors correspond to operations on meaning\n",
    "\n",
    "## The Naive Approach: One-Hot Encoding\n",
    "\n",
    "The simplest way to represent tokens as numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple vocabulary\n",
    "vocab = [\"cat\", \"dog\", \"fish\", \"bird\", \"tree\"]\n",
    "\n",
    "# One-hot encoding: each word is a vector with one \"1\" and rest \"0\"s\n",
    "one_hot = {\n",
    "    \"cat\":  [1, 0, 0, 0, 0],\n",
    "    \"dog\":  [0, 1, 0, 0, 0],\n",
    "    \"fish\": [0, 0, 1, 0, 0],\n",
    "    \"bird\": [0, 0, 0, 1, 0],\n",
    "    \"tree\": [0, 0, 0, 0, 1],\n",
    "}\n",
    "\n",
    "print(\"One-hot representations:\")\n",
    "for word, vec in one_hot.items():\n",
    "    print(f\"  {word:6} â†’ {vec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ¤” Question 1\n",
    "\n",
    "Look at the one-hot vectors above.\n",
    "\n",
    "1. What is the distance between \"cat\" and \"dog\"?\n",
    "2. What is the distance between \"cat\" and \"tree\"?\n",
    "3. Is this what we want? Why or why not?\n",
    "\n",
    "*Think about it before running the next cell.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute distances\n",
    "cat = np.array(one_hot[\"cat\"])\n",
    "dog = np.array(one_hot[\"dog\"])\n",
    "tree = np.array(one_hot[\"tree\"])\n",
    "\n",
    "# Euclidean distance\n",
    "dist_cat_dog = np.linalg.norm(cat - dog)\n",
    "dist_cat_tree = np.linalg.norm(cat - tree)\n",
    "\n",
    "print(f\"Distance between 'cat' and 'dog':  {dist_cat_dog:.2f}\")\n",
    "print(f\"Distance between 'cat' and 'tree': {dist_cat_tree:.2f}\")\n",
    "print()\n",
    "print(\"â†’ With one-hot encoding, ALL words are equally distant from each other!\")\n",
    "print(\"â†’ We lose the semantic relationship: cat and dog are both animals.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Better Approach: Dense Embeddings\n",
    "\n",
    "Instead of sparse one-hot vectors, we use **dense vectors** where:\n",
    "- Each dimension can have any real value\n",
    "- Dimensions capture abstract features (not explicitly named)\n",
    "- **Learning** discovers which dimensions matter\n",
    "\n",
    "Imagine these learned embeddings:\n",
    "\n",
    "```\n",
    "             [is_animal, has_fur, can_fly, is_pet, ...]\n",
    "\"cat\"   â†’   [   0.9,      0.8,     0.0,    0.7,   ...]\n",
    "\"dog\"   â†’   [   0.9,      0.9,     0.0,    0.9,   ...]\n",
    "\"bird\"  â†’   [   0.8,      0.0,     0.9,    0.5,   ...]\n",
    "\"tree\"  â†’   [   0.0,      0.0,     0.0,    0.0,   ...]\n",
    "```\n",
    "\n",
    "Now \"cat\" and \"dog\" are close because they share features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated \"learned\" embeddings (just for illustration)\n",
    "# In reality, these are learned from data by neural networks\n",
    "\n",
    "embeddings = {\n",
    "    \"cat\":   np.array([0.9, 0.8, 0.0, 0.7]),\n",
    "    \"dog\":   np.array([0.9, 0.9, 0.0, 0.9]),\n",
    "    \"fish\":  np.array([0.7, 0.0, 0.0, 0.4]),\n",
    "    \"bird\":  np.array([0.8, 0.0, 0.9, 0.5]),\n",
    "    \"tree\":  np.array([0.0, 0.0, 0.0, 0.0]),\n",
    "}\n",
    "\n",
    "cat = embeddings[\"cat\"]\n",
    "dog = embeddings[\"dog\"]\n",
    "tree = embeddings[\"tree\"]\n",
    "\n",
    "# Now distances reflect semantic similarity!\n",
    "print(\"With dense embeddings:\")\n",
    "print(f\"  Distance 'cat' â†” 'dog':  {np.linalg.norm(cat - dog):.2f}  (close - both pets!)\")\n",
    "print(f\"  Distance 'cat' â†” 'tree': {np.linalg.norm(cat - tree):.2f}  (far - different things)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Cosine Similarity â€” The Standard Measure\n",
    "\n",
    "In practice, we don't use Euclidean distance for embeddings. We use **cosine similarity**.\n",
    "\n",
    "$$\\text{cosine\\_similarity}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}$$\n",
    "\n",
    "This measures the **angle** between vectors, not the distance.\n",
    "\n",
    "**Why cosine similarity?**\n",
    "- Scale-invariant: [1, 2, 3] and [2, 4, 6] have cosine similarity = 1.0\n",
    "- Range: -1 (opposite) to 1 (identical direction)\n",
    "- Works better when embeddings have different magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# Compare all pairs\n",
    "words = list(embeddings.keys())\n",
    "print(\"Cosine similarities between words:\\n\")\n",
    "\n",
    "for i, w1 in enumerate(words):\n",
    "    for w2 in words[i+1:]:\n",
    "        sim = cosine_sim(embeddings[w1], embeddings[w2])\n",
    "        bar = \"â–ˆ\" * int(sim * 20) if sim > 0 else \"\"\n",
    "        print(f\"  {w1:5} â†” {w2:5}: {sim:+.2f}  {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ¤” Question 2\n",
    "\n",
    "Looking at the cosine similarities above:\n",
    "\n",
    "1. Which pair of words has the highest similarity? Does this make sense?\n",
    "2. Why is \"tree\" so different from all animals?\n",
    "3. Why might \"fish\" be somewhat similar to \"cat\" and \"dog\" (both are pets)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Real Embeddings from Pre-trained Models\n",
    "\n",
    "The embeddings above were hand-crafted. In practice, we use **pre-trained models** that learned embeddings from massive datasets.\n",
    "\n",
    "Let's use a real embedding model: `sentence-transformers/all-MiniLM-L6-v2`\n",
    "\n",
    "This model:\n",
    "- Was trained on over 1 billion sentence pairs\n",
    "- Produces 384-dimensional embeddings\n",
    "- Captures semantic meaning surprisingly well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained embedding model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "print(f\"Model loaded!\")\n",
    "print(f\"Embedding dimension: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's embed some sentences\n",
    "sentences = [\n",
    "    \"The cat is sleeping on the couch.\",\n",
    "    \"A dog is resting on the sofa.\",\n",
    "    \"Machine learning transforms data into insights.\",\n",
    "    \"Deep learning models can recognize images.\",\n",
    "    \"The weather is sunny today.\",\n",
    "]\n",
    "\n",
    "# Compute embeddings\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "print(f\"Shape of embeddings: {embeddings.shape}\")\n",
    "print(f\"â†’ {len(sentences)} sentences, each represented by {embeddings.shape[1]} numbers\")\n",
    "print()\n",
    "print(\"First embedding (first 10 values):\")\n",
    "print(f\"  {embeddings[0][:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Visualize the Similarity Matrix\n",
    "\n",
    "A similarity matrix shows how similar each sentence is to every other sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pairwise cosine similarities\n",
    "similarities = cosine_similarity(embeddings)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "im = ax.imshow(similarities, cmap='Blues', vmin=0, vmax=1)\n",
    "plt.colorbar(im, label='Cosine Similarity')\n",
    "\n",
    "# Labels\n",
    "short_labels = [s[:25] + \"...\" if len(s) > 25 else s for s in sentences]\n",
    "ax.set_xticks(range(len(sentences)))\n",
    "ax.set_yticks(range(len(sentences)))\n",
    "ax.set_xticklabels(short_labels, rotation=45, ha='right', fontsize=9)\n",
    "ax.set_yticklabels(short_labels, fontsize=9)\n",
    "\n",
    "# Add values\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(len(sentences)):\n",
    "        ax.text(j, i, f'{similarities[i,j]:.2f}', ha='center', va='center', fontsize=8)\n",
    "\n",
    "ax.set_title('Sentence Similarity Matrix', fontsize=12, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ¤” Question 3\n",
    "\n",
    "Look at the similarity matrix above:\n",
    "\n",
    "1. Which two sentences are most similar (besides the diagonal)?\n",
    "2. Why are sentences 1 and 2 similar? (Hint: read them again)\n",
    "3. Why are sentences 3 and 4 similar?\n",
    "4. Why is sentence 5 different from all others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: The Embedding Space â€” Visualizing High Dimensions\n",
    "\n",
    "Our embeddings have 384 dimensions. We can't visualize 384D directly, but we can project them to 2D using **PCA** (Principal Component Analysis).\n",
    "\n",
    "PCA finds the 2 directions that capture the most variance in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# More diverse sentences for visualization\n",
    "sentences_diverse = [\n",
    "    # Animals\n",
    "    \"The cat is sleeping.\",\n",
    "    \"Dogs are loyal companions.\",\n",
    "    \"Fish swim in the ocean.\",\n",
    "    # Technology\n",
    "    \"Computers process data quickly.\",\n",
    "    \"Software engineers write code.\",\n",
    "    \"Artificial intelligence is advancing.\",\n",
    "    # Nature\n",
    "    \"Mountains are covered in snow.\",\n",
    "    \"The forest is full of trees.\",\n",
    "    \"Rivers flow to the sea.\",\n",
    "]\n",
    "\n",
    "categories = [\"Animals\"] * 3 + [\"Technology\"] * 3 + [\"Nature\"] * 3\n",
    "\n",
    "# Compute embeddings\n",
    "emb = model.encode(sentences_diverse)\n",
    "\n",
    "# Reduce to 2D\n",
    "pca = PCA(n_components=2)\n",
    "emb_2d = pca.fit_transform(emb)\n",
    "\n",
    "print(f\"Original shape: {emb.shape}\")\n",
    "print(f\"After PCA: {emb_2d.shape}\")\n",
    "print(f\"Variance explained: {sum(pca.explained_variance_ratio_)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "colors = {'Animals': 'red', 'Technology': 'blue', 'Nature': 'green'}\n",
    "\n",
    "for cat in set(categories):\n",
    "    mask = [c == cat for c in categories]\n",
    "    ax.scatter(emb_2d[mask, 0], emb_2d[mask, 1], \n",
    "               c=colors[cat], label=cat, s=150, alpha=0.7)\n",
    "\n",
    "# Add labels\n",
    "for i, sent in enumerate(sentences_diverse):\n",
    "    short = sent[:20] + \"...\" if len(sent) > 20 else sent\n",
    "    ax.annotate(short, (emb_2d[i, 0], emb_2d[i, 1]), \n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "ax.set_xlabel('PCA Component 1', fontsize=11)\n",
    "ax.set_ylabel('PCA Component 2', fontsize=11)\n",
    "ax.set_title('Embedding Space (2D projection)', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ¤” Question 4\n",
    "\n",
    "Look at the 2D visualization:\n",
    "\n",
    "1. Do sentences from the same category cluster together?\n",
    "2. Which category seems most tightly clustered? Why might that be?\n",
    "3. PCA only explains a fraction of the variance. What does this tell us about the embedding space?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: Semantic Search â€” A Practical Application\n",
    "\n",
    "One of the most powerful applications of embeddings is **semantic search**:\n",
    "\n",
    "Given a query, find the most similar items in a database.\n",
    "\n",
    "Unlike keyword search, semantic search understands **meaning**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our \"database\" of scientific topics\n",
    "database = [\n",
    "    \"CRISPR gene editing technology for treating genetic diseases\",\n",
    "    \"Protein folding prediction using deep learning models\",\n",
    "    \"Climate change impact on marine ecosystems\",\n",
    "    \"Quantum computing algorithms for optimization problems\",\n",
    "    \"Drug discovery using molecular simulations\",\n",
    "    \"Machine learning for analyzing medical images\",\n",
    "    \"Renewable energy storage in batteries\",\n",
    "    \"Neuroimaging techniques for brain research\",\n",
    "]\n",
    "\n",
    "# Pre-compute database embeddings\n",
    "db_embeddings = model.encode(database)\n",
    "\n",
    "print(f\"Database: {len(database)} items\")\n",
    "print(f\"Embedding shape: {db_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, top_k=3):\n",
    "    \"\"\"Find the most similar items to a query.\"\"\"\n",
    "    # Embed the query\n",
    "    query_emb = model.encode([query])\n",
    "    \n",
    "    # Compute similarities with all database items\n",
    "    similarities = cosine_similarity(query_emb, db_embeddings)[0]\n",
    "    \n",
    "    # Get top-k indices\n",
    "    top_indices = similarities.argsort()[::-1][:top_k]\n",
    "    \n",
    "    print(f\"Query: '{query}'\\n\")\n",
    "    print(\"Most similar items:\")\n",
    "    for rank, idx in enumerate(top_indices, 1):\n",
    "        print(f\"  {rank}. [{similarities[idx]:.3f}] {database[idx]}\")\n",
    "\n",
    "# Try a search\n",
    "semantic_search(\"How can AI help with biology?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Try Your Own Searches\n",
    "\n",
    "Modify the query below and run the search. Try queries related to your research field!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try different queries!\n",
    "my_query = \"neural networks for medical diagnosis\"  # <-- Modify this!\n",
    "\n",
    "semantic_search(my_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ¤” Question 5\n",
    "\n",
    "1. Try a query that doesn't use any exact words from the database (e.g., \"AI for healthcare\"). Does it still find relevant results?\n",
    "2. Why does semantic search work even without keyword matching?\n",
    "3. Can you think of cases where semantic search might fail or give unexpected results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Summary: Key Takeaways\n",
    "\n",
    "## What We Learned\n",
    "\n",
    "1. **Embeddings are dense vector representations** where similar things have similar vectors\n",
    "\n",
    "2. **The pipeline**: Raw data â†’ Tokens â†’ Token IDs â†’ Embeddings\n",
    "\n",
    "3. **Cosine similarity** is the standard way to measure embedding similarity\n",
    "\n",
    "4. **Pre-trained models** (like Sentence-BERT) have learned powerful embeddings from massive datasets\n",
    "\n",
    "5. **Applications**: Semantic search, clustering, classification, recommendation\n",
    "\n",
    "## Key Insight\n",
    "\n",
    "> **Meaning becomes geometry.** When you have good embeddings, reasoning about meaning becomes reasoning about distances and directions in vector space.\n",
    "\n",
    "## What's Next\n",
    "\n",
    "In **Part 2**, we'll explore embeddings for different scientific domains:\n",
    "- Text embeddings for scientific abstracts\n",
    "- Molecular embeddings (SMILES)\n",
    "- Protein embeddings (amino acid sequences)\n",
    "- DNA embeddings (nucleotide sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Reflection Questions\n",
    "\n",
    "Before moving to Part 2, think about:\n",
    "\n",
    "1. **In your research domain**, what data do you work with that could be embedded? (text, sequences, structures, images?)\n",
    "\n",
    "2. **What would \"similarity\" mean** in your domain? What should be close in embedding space?\n",
    "\n",
    "3. **What tasks** could you solve if you had good embeddings for your data? (search, clustering, classification?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
